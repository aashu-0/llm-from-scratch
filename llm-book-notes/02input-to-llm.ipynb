{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of chars: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open ('the-verdict.txt', 'r', encoding= 'utf-8' ) as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(f'total number of chars: {len(raw_text)}')\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "# splitting char on whitespace (\\s)\n",
    "import re\n",
    "text = 'Hello, world. This, is a test.'\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,', 'world.', 'This,', 'is', 'a', 'test.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can remove the whitespace also\n",
    "result = [item for item in result if item.split()]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "# we can include the , . also\n",
    "result = re.split(r'([,.]|\\s)', text)\n",
    "\n",
    "#remove whitespace\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = 'dark is one of the best show i have ever watched'\n",
    "# t1.strip()\n",
    "# print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "# include all the punctations and apply to our text \n",
    "preprocessed = re.split(r'([,.;:?_!\"()\\']|--|\\s)', raw_text)\n",
    "\n",
    "preprocessed = [item for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokens to token IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " in order to convert tokens to tokens ids,\n",
    " \n",
    " we first have to have a vocabulary to map words to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab\n",
    "\n",
    "all_words = sorted(set(preprocessed)) #set: for unique char\n",
    "vocab_size = len(all_words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token: int for int, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's functionize all this\n",
    "- first encode method to convert text to token ids (text -> tokens -> token ids)\n",
    "\n",
    "- and a decode method to convert token ids back to  text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex Pattern\n",
    "- `\\s+`: one or more whitespaces\n",
    "- `[,.;:?_!\"()\\']`: matches any of `, . ? ! \" ( ) '`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a simple text tokenizer\n",
    "\n",
    "class SimpleTokenizerV1():\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.;:?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)   # removes the unnecessary spaces before punctuation\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 44, 149, 1003, 57, 38, 818, 115, 256, 486, 1002, 115, 500, 435, 392, 908, 585, 1077, 709, 7, 56, 2, 850, 663]\n"
     ]
    }
   ],
   "source": [
    "# let's do it for a example text\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"I HAD always thought Jack Gisburn rather a cheap genius though a\n",
    "good fellow enough so it was no. It's me\"\"\"\n",
    "\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I HAD always thought Jack Gisburn rather a cheap genius though a good fellow enough so it was no. It' s me\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep in mind that our vocabulary is limited to \"The Verdict\" txt file.\n",
    "\n",
    "we will not able to tokenize any word outside our training set..here the short story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex\n",
    "# txt = \"Hello, aashutosh\"\n",
    "# print(tokenizer.encode(txt))   # -> raise a KeyError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can (or should) extend our vocab with additional tokens like \n",
    "```<startoftext>, <endoftext>, <unk>``` etc\n",
    "\n",
    "/ these special tokens are different for different llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "# modify of vocab to include two special tokens -> <|unk|>, <|endoftext|>\n",
    "\n",
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend(['<|unk|>', '<|endoftext|>'])\n",
    "\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1130 + 2 special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('younger', 1127),\n",
       " ('your', 1128),\n",
       " ('yourself', 1129),\n",
       " ('<|unk|>', 1130),\n",
       " ('<|endoftext|>', 1131)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.items())[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer class that includes special tokens\n",
    "\n",
    "class SimpleTokenizerV2():\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.;:?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "\n",
    "        preprocessed = [item if item in self.str_to_int\n",
    "                        else '<|unk|>' for item in preprocessed]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello On reflection, it really was a tempting problem. <|endoftext|> To accuse his wife would have been too easy--In India\n"
     ]
    }
   ],
   "source": [
    "txt1 = 'Hello On reflection, it really was a tempting problem.'\n",
    "txt2 = 'To accuse his wife would have been too easy--In India'\n",
    "\n",
    "txt = ' <|endoftext|> '.join((txt1, txt2))\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1130, 75, 828, 5, 585, 821, 1077, 115, 981, 796, 7, 1131, 102, 125, 549, 1103, 1120, 530, 208, 1020, 375, 6, 55, 1130]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab=vocab)\n",
    "ids = tokenizer.encode(txt)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|> On reflection, it really was a tempting problem. <|endoftext|> To accuse his wife would have been too easy -- In <|unk|>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional special tokens\n",
    "```[BOS], [EOS], [PAD]```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT models use a *byte pair encoding* tokenizer\n",
    "\n",
    "How BTE handles unknown words?\n",
    "- break down the unk word into characers and subwords, and these subwords can then tokenized.\n",
    "- so we can assign multiple token ids to a single words.\n",
    "- no need of <|unk|> token to handle unknwn words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a library called tiktoken\n",
    "Why tiktoken?\n",
    "- efficient (written in Rust)\n",
    "- optimized for openai models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BPE in a nutshell**\n",
    "- start with individual characters\n",
    "- find the most common pair\n",
    "- merge it to the vocab\n",
    "- keep repeating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ( \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "        \"of someunknownPlace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "integers = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ak -> 33901\n",
      "w -> 86\n",
      "ir -> 343\n",
      "w -> 86\n",
      "  -> 220\n",
      "ier -> 959\n"
     ]
    }
   ],
   "source": [
    "str = 'Akwirw ier'\n",
    "ids = tokenizer.encode(str)\n",
    "\n",
    "for id in ids:\n",
    "    print(f'{tokenizer.decode([id])} -> {id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Sampling using Sliding window -> generating input-target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will create input-target pairs for the next word prediction task\n",
    "- x -> input tokens\n",
    "- y -> targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [290, 4920, 2241, 287]\n",
      "y:       [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4  # max number of token in the input\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f'x : {x}')\n",
    "print(f'y:       {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Token --> Target Token\n",
      "[290] --> 4920\n",
      "[290, 4920] --> 2241\n",
      "[290, 4920, 2241] --> 287\n",
      "[290, 4920, 2241, 287] --> 257\n"
     ]
    }
   ],
   "source": [
    "# inputs and targets tokens\n",
    "print(f'Input Token --> Target Token')\n",
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f'{context} --> {desired}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text --> Target text\n",
      " and -->  established\n",
      " and established -->  himself\n",
      " and established himself -->  in\n",
      " and established himself in -->  a\n"
     ]
    }
   ],
   "source": [
    "print(f'Input text --> Target text')\n",
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(f'{tokenizer.decode(context)} --> {tokenizer.decode([desired])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom pytorch dataset and dataloader\n",
    "- `Dataset` -> manages dataset\n",
    "- `Dataloader` -> feeds data into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# 1. custom dataset\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.inputs_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # tokenize the text\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        #uses a sliding window approach\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i: i+max_length]\n",
    "            target_chunk = token_ids[i+1: i+1+max_length]\n",
    "\n",
    "            self.inputs_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    # return total num of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.inputs_ids)\n",
    "    \n",
    "    # return a single row\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs_ids[index], self.target_ids[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. custom dataloader\n",
    "def create_dataloders_v1(txt,\n",
    "                         batch_size=4,\n",
    "                         max_length= 256,\n",
    "                         stride= 128,  # stride -> num of positions the input shift across batches\n",
    "                         shuffle= True,\n",
    "                         drop_last = True,\n",
    "                         num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last, # drops the last batch if it is shorter than the batch_size\n",
    "                            num_workers=num_workers)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloders_v1(raw_text,\n",
    "                                  batch_size=1,\n",
    "                                  max_length=4,\n",
    "                                  stride=1,\n",
    "                                  shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets: \n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "# batch size greater than 1\n",
    "dataloader = create_dataloders_v1(raw_text,\n",
    "                                  batch_size=8,\n",
    "                                  max_length=4,\n",
    "                                  stride=4,  # stride = max_length (to avoid overlap since more overlap => overfitting)\n",
    "                                  shuffle= False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(f'Inputs: \\n {inputs}')\n",
    "print(f'\\nTargets: \\n {targets}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### token embeddings\n",
    "- learned during training and stored as a lookup table (called `embedding matrix`)\n",
    "- first initialized with random values and then updated during the course of training.\n",
    "\n",
    "`vocab_size = V`\n",
    "\n",
    "`output_dim = d`\n",
    "\n",
    "`embedding matrix (E) shape: (V,d)`\n",
    "\n",
    "each token's embedding is a row in the embedding matrix, which is learned via backprop\n",
    "\n",
    "**embedding vector of token at index i in the vocab = E[i]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in GPT3,\n",
    "- vocab size, V = 50,257\n",
    "- hidden size, d = 12,288\n",
    "\n",
    "GPT3's token embedding matrix has shape `(50,257, 12,288)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "import torch\n",
    "input_ids = torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.9269,  1.4873, -0.4974],\n",
       "        [ 0.4396, -0.7581,  1.0783],\n",
       "        [ 0.8008,  1.6806,  0.3559],\n",
       "        [-0.6866,  0.6105,  1.3347],\n",
       "        [-0.2316,  0.0418, -0.2516],\n",
       "        [ 0.8599, -0.3097, -0.3957]], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 6\n",
    "output_dim = 3 #d\n",
    "\n",
    "# initalize a embedding layer\n",
    "torch.manual_seed(42)\n",
    "embed_layer = nn.Embedding(vocab_size, output_dim)\n",
    "embed_layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above matrix is called embedding matrix.\n",
    "\n",
    "we are essentially converting a single token id into a `d` dim embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6866,  0.6105,  1.3347]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = torch.tensor([3])\n",
    "embed_layer(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8008,  1.6806,  0.3559],\n",
       "        [-0.6866,  0.6105,  1.3347],\n",
       "        [ 0.8599, -0.3097, -0.3957],\n",
       "        [ 0.4396, -0.7581,  1.0783]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortcoming of these embeddings:\n",
    "\n",
    "1. same token id always gets mapped to the same vector representation, regardless of position of the token... no positional info\n",
    "\n",
    "2. also self attention mechanism is **position-agnostic** (means does not have a bulit in sense of word order, therfore need to add positional info to the llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "` input embedding = token embedding + positional embedding`\n",
    "\n",
    "Types of pos embeddings:\n",
    "1. Absolute embeddings (associated with absolute position of tokens)\n",
    "2. Relative embeddings (based on relative position between words)\n",
    "\n",
    "GPT uses absolute pos embeddings that are learned during the training process.\n",
    "Btw, the original transformer model uses fixed pos embedding (*sin and cos formulas in attention paper*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed each token into a 256-dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Ids: \n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape: \n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length = 4\n",
    "dataloader = create_dataloders_v1(raw_text,\n",
    "                                  batch_size=8,\n",
    "                                  max_length=max_length,\n",
    "                                  stride=max_length,\n",
    "                                  shuffle = False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "\n",
    "print(f'Token Ids: \\n {inputs}')\n",
    "print(f'\\nInputs shape: \\n {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token id tensor into 256- dim vectors\n",
    "\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each token id is embedded into a 256 dim vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = nn.Embedding(context_length, output_dim)\n",
    "\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)\n",
    "# print(torch.arange(context_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# adding pos_embedding with token_embedding\n",
    "input_embeddings = token_embeddings + pos_embeddings  # pytorch broadcasting\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, these input embedding are used as a input for the main LLM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.8317e-01,  2.1782e+00,  3.8856e+00,  2.5868e+00,  1.4441e+00,\n",
      "        -7.2869e-01,  2.4407e+00,  3.5799e-01,  3.2556e+00, -1.2108e-02,\n",
      "        -1.2161e+00, -1.1384e+00,  2.9287e+00,  2.3976e+00,  1.7161e+00,\n",
      "         2.6013e+00,  8.5243e-01,  1.6218e+00, -2.6531e-01, -9.6503e-01,\n",
      "        -4.8168e-01,  7.6193e-02, -9.9844e-01, -9.9940e-01, -9.8121e-01,\n",
      "         6.1716e-01,  1.3799e+00,  3.5311e-01, -6.7868e-01, -1.1240e-01,\n",
      "        -5.2592e-01, -5.1606e-01,  2.5461e-01,  7.8465e-01, -1.5667e+00,\n",
      "        -2.3691e-01, -1.3758e-02, -1.4461e+00,  1.7381e+00,  7.3556e-01,\n",
      "        -2.1020e+00, -1.0255e+00, -5.4484e-01, -3.5187e-01, -2.4607e-01,\n",
      "         1.5227e+00, -1.2309e+00, -1.4676e-01, -1.2751e+00,  1.8039e+00,\n",
      "         3.2581e-01, -2.9651e-02, -2.2289e+00, -8.5137e-01,  9.5349e-01,\n",
      "        -2.6317e+00,  2.0894e+00, -2.3409e+00, -6.6308e-01, -1.3241e+00,\n",
      "         1.3093e+00, -1.7003e+00,  1.0733e+00,  1.6118e+00,  1.4364e+00,\n",
      "        -6.5225e-01,  2.6143e+00,  3.6995e-01,  7.1542e-01, -1.0636e+00,\n",
      "        -1.2387e+00, -1.2017e+00, -2.4244e+00,  1.2199e+00,  2.0361e+00,\n",
      "        -1.3630e+00, -8.5078e-02,  2.8778e+00, -3.1955e+00,  7.7338e-01,\n",
      "        -1.9096e+00, -1.2721e-01,  2.2262e-01,  2.0785e-01, -1.4214e+00,\n",
      "         1.5045e+00,  1.0386e+00, -4.6592e-01,  1.1503e+00, -6.9842e-01,\n",
      "         7.7772e-01,  4.5716e-01,  1.0141e+00, -2.9853e-01,  1.5615e+00,\n",
      "        -1.2382e+00, -2.1852e+00,  9.2835e-01,  1.0575e+00,  3.6129e-01,\n",
      "         4.7202e-01,  9.9552e-01,  1.7087e+00, -4.0330e+00, -1.6143e-01,\n",
      "        -1.2294e+00, -1.4749e+00,  1.3134e+00, -4.0374e-01, -8.3369e-01,\n",
      "        -7.0197e-02,  8.8584e-01, -1.3174e+00, -1.5932e+00,  6.1235e-01,\n",
      "         1.3601e+00, -5.1486e-01,  1.5782e+00,  4.8211e-02, -1.6922e+00,\n",
      "         1.5982e+00,  1.0995e+00,  9.7295e-01, -1.1391e-01,  5.3732e-01,\n",
      "        -7.4446e-01,  2.2957e+00, -1.0852e+00,  1.1743e+00,  8.5776e-01,\n",
      "         1.3884e-01,  5.3702e-01, -3.7898e-01,  1.6119e+00,  2.1429e-01,\n",
      "        -9.5486e-01,  5.8942e-01,  1.0111e+00,  3.2479e-01, -1.2624e+00,\n",
      "         1.3184e+00,  1.6081e+00,  8.8200e-02,  2.7856e-01, -4.3906e-01,\n",
      "         3.6615e-02,  7.9869e-02,  2.5629e-01,  6.1445e-01,  8.1504e-01,\n",
      "         1.7674e+00, -4.6901e-01, -1.2464e+00, -2.1686e-02, -1.3958e+00,\n",
      "         3.2395e+00, -6.5744e-01,  1.1099e+00, -1.5961e+00,  1.6299e+00,\n",
      "         9.6195e-02, -3.9476e-01,  1.0831e+00, -8.6785e-01,  2.6964e+00,\n",
      "        -1.8049e+00, -1.8519e+00, -1.3887e+00,  2.1183e+00, -1.0962e+00,\n",
      "         1.4410e+00, -9.7517e-01, -3.4260e+00,  1.9384e+00,  1.6702e+00,\n",
      "         8.1936e-01,  1.7440e-01,  1.3555e-01,  8.3288e-01,  1.8657e-01,\n",
      "        -7.8939e-01,  1.9318e+00, -1.6248e+00, -4.7512e-01,  6.3033e-01,\n",
      "        -2.6652e+00,  1.5124e-01, -1.5244e+00,  7.1758e-01, -6.9412e-01,\n",
      "        -1.5144e+00,  2.1068e-01, -1.0766e+00,  9.8241e-01,  2.3860e-01,\n",
      "         2.1946e+00, -1.1166e-01,  6.8409e-01, -2.2231e-01, -1.7111e+00,\n",
      "        -3.2253e-02,  2.9161e+00, -1.3159e+00,  8.2219e-01,  2.4574e+00,\n",
      "         2.7991e-01, -9.8540e-02,  2.8372e-01,  2.1727e+00,  5.6623e-01,\n",
      "         2.8799e-01, -9.4402e-01, -5.2146e-01,  3.1154e-03,  1.6410e-01,\n",
      "        -1.3675e+00,  4.5329e-01,  6.2337e-01,  1.7091e+00, -1.6281e+00,\n",
      "         1.5002e+00,  3.9453e-02, -9.4684e-02, -4.3906e-02,  8.6332e-01,\n",
      "         2.1267e+00,  1.8507e+00,  6.2714e-01,  1.1051e+00, -6.5215e-02,\n",
      "        -1.0316e+00, -5.4944e-01,  1.3382e-01,  7.7626e-01,  5.8768e-01,\n",
      "         3.1274e+00, -1.3963e-01,  1.9994e+00, -2.6408e+00, -2.9642e-01,\n",
      "        -5.3517e-01, -1.3628e-01, -7.8533e-01, -2.8720e-01,  1.0087e+00,\n",
      "        -8.0937e-01,  1.3022e+00, -2.3802e-01,  2.7292e-01, -7.0240e-01,\n",
      "        -2.1162e+00,  6.0885e-01,  9.6082e-01, -2.3117e+00,  4.6306e-02,\n",
      "        -1.1299e+00], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Embedding pipeline**\n",
    "\n",
    "input text -> tokens -> token ids -> token embedding + pos embedding -> input embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
