{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashu-0/llm-from-scratch/blob/main/llm_book_notes/07instruct-fine-tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLN12aXxnqCe"
      },
      "source": [
        "**Instruction fine tuning**\n",
        "- also called supervised instruction fine tuning\n",
        "- tuning llm to follow instructions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Preparing the dataset"
      ],
      "metadata": {
        "id": "gqSVZCg6n4Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Download the Stanford Alpaca dataset from github"
      ],
      "metadata": {
        "id": "ILOcvWqPpfyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import urllib.request\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/refs/heads/main/alpaca_data.json\"\n",
        "\n",
        "file_path = 'alpaca_data.json'\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "# load\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "print(f'Number of entries: {len(dataset)}')"
      ],
      "metadata": {
        "id": "dN_nNbNQnvPQ",
        "outputId": "53c576c5-e90d-43a2-9b9a-e74233864187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 52002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HlE9moQwnqCi",
        "outputId": "3d4a16f2-1bc5-4b9a-fa8f-781f532b9453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 10000\n"
          ]
        }
      ],
      "source": [
        "# a subset of the dataset -> 10k samples\n",
        "\n",
        "import random\n",
        "subset_size = 10000\n",
        "random.seed(42)\n",
        "subset_data = random.sample(dataset, subset_size) # a list of dictionaries\n",
        "\n",
        "# save\n",
        "subset_file_path = 'alpaca_subset.json'\n",
        "\n",
        "# to convert list to json-formatted string\n",
        "with open(subset_file_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(subset_data, f, indent=4)\n",
        "\n",
        "print(f'Number of entries: {len(subset_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ndmhhUpvnqCj"
      },
      "outputs": [],
      "source": [
        "# subset_data[:18]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the subset_data\n",
        "\n",
        "with open(subset_file_path, 'r', encoding='utf-8') as f:\n",
        "    subset_dataset = json.load(f)\n",
        "\n",
        "print(f'Number of entries: {len(subset_dataset)}')"
      ],
      "metadata": {
        "id": "Yj6cb4KzsJSQ",
        "outputId": "02c8a247-0343-4d12-accd-61892b70e39d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Example:\\n {subset_dataset[4000]}') # no input section"
      ],
      "metadata": {
        "id": "h_IhYoeGsheI",
        "outputId": "4295e770-9656-4269-e3ee-8dd26030b930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:\n",
            " {'instruction': 'Create a simile about the sound of a waterfall', 'input': '', 'output': 'The sound of a waterfall is like a roaring lion - loud, powerful, and majestic.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Example:\\n {subset_dataset[5000]}')"
      ],
      "metadata": {
        "id": "A_odMQW8urv2",
        "outputId": "07a62060-213c-4fa3-9849-6b582a5f7b57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:\n",
            " {'instruction': 'You are provided with the following title. Write a summary of the article with a length of no more than 60 words:', 'input': '\"5 Reasons Music Education is Important for Young People\"', 'output': 'Music education has numerous benefits for young people, from improving social skills and fostering teamwork to aiding in self-expression and boosting confidence. It can also positively influence academic ability and mental health. This article explores five reasons why music education is important for young people.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so the structure of the dataset looks like:\n",
        "\n",
        "\n",
        "```\n",
        "{'instruction\":\n",
        "  'input':  #may be empty\n",
        "  'output':}\n",
        "```\n",
        "there are various ways to format these entries:\n",
        "- `Alpaca prompt style`\n",
        "- `Phi-3 prompt style`\n"
      ],
      "metadata": {
        "id": "mcgUXRJLs3MX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Implementing the formatting function"
      ],
      "metadata": {
        "id": "-BrCFCxStmBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "  instruction_txt = (\n",
        "      f\"Below is an instruction that describes a task. \"\n",
        "      f\"Write a response that appropriately completes the request.\\n\\n\"\n",
        "      f\"### Instruction:\\n{entry['instruction']}\"\n",
        "  )\n",
        "  input_text = (\n",
        "      f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else ''\n",
        "  )\n",
        "  return instruction_txt + input_text\n"
      ],
      "metadata": {
        "id": "NwPvC0XJsqAV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(subset_dataset[5000])\n",
        "desired_response = f\"\\n\\n### Response:\\n{subset_dataset[5000]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "id": "ZPCvopLduljG",
        "outputId": "be789ca1-0408-49d4-fc89-cfb9d6258766",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "You are provided with the following title. Write a summary of the article with a length of no more than 60 words:\n",
            "\n",
            "### Input:\n",
            "\"5 Reasons Music Education is Important for Young People\"\n",
            "\n",
            "### Response:\n",
            "Music education has numerous benefits for young people, from improving social skills and fostering teamwork to aiding in self-expression and boosting confidence. It can also positively influence academic ability and mental health. This article explores five reasons why music education is important for young people.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train Test Split"
      ],
      "metadata": {
        "id": "SHxyLt_Kvvpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = int(len(subset_dataset)*0.85)\n",
        "test_set = int(len(subset_dataset)*0.1)\n",
        "val_set = len(subset_dataset) - train_set - test_set\n",
        "\n",
        "train_data = subset_dataset[:train_set]\n",
        "test_data = subset_dataset[train_set:train_set+test_set]\n",
        "val_data = subset_dataset[train_set+test_set:]\n",
        "\n",
        "print(f'Train set size: {len(train_data)}')\n",
        "print(f'Test set size: {len(test_data)}')\n",
        "print(f'Validation set size: {len(val_data)}')"
      ],
      "metadata": {
        "id": "3KXJhaLRupYe",
        "outputId": "b1f69bae-5ad1-4c1e-d7de-f4132b042213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 8500\n",
            "Test set size: 1000\n",
            "Validation set size: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Organizing data into batches"
      ],
      "metadata": {
        "id": "nslTe1olwPH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`collate` function in pytorch\n",
        "- used to batch samples together into a single batch\n",
        "- allows custom preprocessing, when dealing with variable-length data\n",
        "\n",
        "1. `default_collate`\n",
        "- stackes tensor along the first dim\n",
        "- convert lists into tensors\n",
        "- leaves dic and other data structures untouched\n",
        "2. `collate_fn`\n",
        "- for creating custom collate function"
      ],
      "metadata": {
        "id": "Pc7zp_gzwc_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Collate function**\n",
        "\n",
        "1. format data\n",
        "2. tokenize\n",
        "3. adjust them to have same length using padding tokens\n",
        "4. create target token ids\n",
        "  * inputs shifted by `1`\n",
        "5. replace certain pad tokens\n",
        "  * why do not contain useful info so excluded from loss computation\n",
        "  * `ignore_index`: placeholder value(`-100`)\n",
        "\n"
      ],
      "metadata": {
        "id": "ecrRbrB-yHm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Instruction dataset class"
      ],
      "metadata": {
        "id": "abKUIstV0Y4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.encode_texts = []\n",
        "    for entry in data:\n",
        "      input_with_instruction = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = input_with_instruction + response_text\n",
        "      self.encode_texts.append(\n",
        "          tokenizer.encode(full_text)\n",
        "      )\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "     return self.encode_texts[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "P7RNq-GY0n1I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Custom Batch collate function"
      ],
      "metadata": {
        "id": "ejphi6jd3jCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id= 50256,\n",
        "    allowed_max_length=None,\n",
        "    ignore_index=-100,\n",
        "    device = 'cpu'):\n",
        "\n",
        "  batch_max_length = max(len(item) for item in batch)\n",
        "  inputs_lst, targets_lst = [], []\n",
        "  for item in batch:\n",
        "    new_item = item.copy()\n",
        "    new_item += [pad_token_id]\n",
        "\n",
        "    padded = (new_item + [pad_token_id]* (batch_max_length - len(item)))\n",
        "    inputs= torch.tensor(padded[:-1])\n",
        "    targets= torch.tensor(padded[1:])\n",
        "\n",
        "    mask = targets == pad_token_id\n",
        "    indices = torch.nonzero(mask).squeeze() # returns the indices of True values\n",
        "    if indices.numel() >1:\n",
        "      targets[indices[1:]] = ignore_index\n",
        "\n",
        "    if allowed_max_length is not None:\n",
        "      inputs = inputs[:allowed_max_length]\n",
        "      targets = targets[:allowed_max_length]\n",
        "\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "\n",
        "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "  return inputs_tensor, targets_tensor\n"
      ],
      "metadata": {
        "id": "GLoBwzGY3n4r"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "input1 = [0,1,2,3,4]\n",
        "input2 = [5,6]\n",
        "input3 = [7,8,9]\n",
        "\n",
        "batch = [input1, input2, input3]\n",
        "\n",
        "input, target = custom_collate_fn(batch)\n",
        "print(input)\n",
        "print(target)"
      ],
      "metadata": {
        "id": "yZ3MMTyu3n01",
        "outputId": "b69f9b70-b528-4757-e7bf-8b257d8169fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why `-100`?\n",
        "\n",
        "by default `ignore_index` in `cross_entropy()` is equal to `-100`.\n",
        "\n",
        "therefore, it ignores targets labeled with -100"
      ],
      "metadata": {
        "id": "drBrpXOe88DJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masking out the instruction text- so that model focuses on generating accurate responses ratehr than memorizing instructions.\n",
        "\n",
        "we do later"
      ],
      "metadata": {
        "id": "49QTXQwO9ath"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating dataloaders"
      ],
      "metadata": {
        "id": "PhrzJAon-Ttz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "hvQYI40d1fge",
        "outputId": "144c37b7-c1aa-450a-9cde-f212ec98324a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix or pre-fill some argument in custom_collate_function\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "custom_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    allowed_max_length=1024,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "OU-tPPhH-hsh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "QHlRyY2j_iz4",
        "outputId": "831af36b-78fb-4f49-a379-3ecf6497e367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "-CHPb3yj_cV7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "a4gBllU-_HxU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_loader:\n",
        "  print(f'Inputs: {inputs.shape}, Targets: {targets.shape}')\n",
        "  break"
      ],
      "metadata": {
        "id": "bf7R4JAEAZnI",
        "outputId": "a90ae7fc-7c1b-477f-ffc6-6ee9010c37d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: torch.Size([8, 147]), Targets: torch.Size([8, 147])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading Pretrained LLM"
      ],
      "metadata": {
        "id": "dSgqkHPNBPaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting scripts from github\n",
        "!git clone https://github.com/aashu-0/llm-from-scratch.git\n",
        "%cd llm-from-scratch/llm_book_notes"
      ],
      "metadata": {
        "id": "ICcOslIPAi-d",
        "outputId": "2460e81c-c5a6-40a3-f8d9-6568c6546eab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-from-scratch'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 120 (delta 63), reused 78 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (120/120), 164.39 KiB | 2.11 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "/content/llm-from-scratch/llm_book_notes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/llm-from-scratch/llm_book_notes')"
      ],
      "metadata": {
        "id": "98QVze3pDO8i"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get gpt_download.py from @rasbt github\n",
        "import urllib.request\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/\"\n",
        "    \"LLMs-from-scratch/main/ch05/\"\n",
        "    \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "urllib.request.urlretrieve(url, \"gpt_download.py\")"
      ],
      "metadata": {
        "id": "8YFmNihMDecq",
        "outputId": "0f77b6d3-46cb-4e53-e735-6f8e006d5f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x78de98aafe90>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from load_weights import load_weights_into_gpt\n",
        "from GPT import GPTModel\n",
        "from gpt_download import download_and_load_gpt2\n",
        "\n"
      ],
      "metadata": {
        "id": "CBFDzZPDDS2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}