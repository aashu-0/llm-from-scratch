{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashu-0/llm-from-scratch/blob/main/llm_book_notes/05pretraining-gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting scripts from github\n",
        "!git clone https://github.com/aashu-0/llm-from-scratch.git\n",
        "%cd llm-from-scratch/llm_book_notes"
      ],
      "metadata": {
        "id": "8Rv95SrcAlq2",
        "outputId": "89ee4f69-eb4a-4a25-9453-277ab0f8b52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-from-scratch'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 64 (delta 30), reused 41 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (64/64), 80.90 KiB | 637.00 KiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/llm-from-scratch/llm_book_notes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/llm-from-scratch/llm_book_notes')"
      ],
      "metadata": {
        "id": "UhOM8bgLC6V6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK4DeVYJ8rom"
      },
      "source": [
        "#### **Pretraining on unlabeled data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1H7VsCB8rop"
      },
      "source": [
        "To access weight of any layer : `layer_name.weight`\n",
        "\n",
        "To access all model trainable parameters: `model.parameters()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cstLjUCp8ror",
        "outputId": "4f3c8fff-ff7c-49ea-d17a-67fc6bb23545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attn): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 1. Text Generation\n",
        "\n",
        "import torch\n",
        "from GPT import GPTModel\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    'vocab_size': 50257,\n",
        "    'context_length': 256,\n",
        "    'emb_dim': 768,\n",
        "    'n_heads':12,\n",
        "    'n_layers': 12,\n",
        "    'drop_rate': 0.1,\n",
        "    'qkv_bias': False\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(config=GPT_CONFIG_124M)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "E7Po_2c2EL8O",
        "outputId": "c269a1de-65d9-4b37-8f21-73c6ae55e283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "66HsPxNl8rov"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from GPT import generate_text_simple\n",
        "\n",
        "# function to text to token_id and token_ids_to_text\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special= {'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    decoded_text = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
        "    return decoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DxyqjXW08row",
        "outputId": "d165c4d0-9c21-4c67-bc95-866c5ead7700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text: Every Effort Moves you\n",
            "Output Text: Every Effort Moves you finisheduxeHandle appropriation pigment cotton feellike poll liberate\n"
          ]
        }
      ],
      "source": [
        "start_context = 'Every Effort Moves you'\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "input_ids = text_to_token_ids(start_context, tokenizer)\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model = model,\n",
        "    idx = input_ids,\n",
        "    max_new_tokens = 10,\n",
        "    context_size= GPT_CONFIG_124M['context_length']\n",
        ")\n",
        "\n",
        "output = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "print(f'Input Text: {start_context}')\n",
        "print(f'Output Text: {output}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.encode('every effort moves you'))\n",
        "print(tokenizer.encode('I really like chocolate'))"
      ],
      "metadata": {
        "id": "eaVZ-KLhEknj",
        "outputId": "1f07dd82-0ffa-4711-ed50-d6243f08a163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16833, 3626, 6100, 345]\n",
            "[40, 1107, 588, 11311]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn0w5L-n8rox"
      },
      "source": [
        "#### 1. Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2J8rGFeP8roy"
      },
      "outputs": [],
      "source": [
        "# inputs and targets (shifting concept)\n",
        "inputs = torch.tensor([[16833, 3626, 6100],\n",
        "                       [40, 1107, 588]])\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345],\n",
        "                        [1107, 588, 11311]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6YDdOe468roz",
        "outputId": "8c9cd061-901c-4f78-cfef-ced232f8ae8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
            "         [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
            "         [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217]],\n",
            "\n",
            "        [[-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
            "         [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
            "         [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]]])\n",
            "\n",
            "Probas Shape: torch.Size([2, 3, 50257])\n",
            "\n",
            "Probas: tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
            "          6.9776e-06, 1.8776e-05],\n",
            "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
            "          6.0103e-06, 1.3571e-05],\n",
            "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
            "          1.4094e-05, 1.3526e-05]],\n",
            "\n",
            "        [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
            "          3.4784e-05, 1.4239e-05],\n",
            "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
            "          1.1390e-05, 1.5559e-05],\n",
            "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
            "          5.8203e-05, 1.3698e-05]]])\n"
          ]
        }
      ],
      "source": [
        "# calculating probability scores\n",
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "print(f'Logits: {logits}\\n')\n",
        "print(f'Probas Shape: {probas.shape}\\n')   #[batch_size, n_tokens, emb_dim]\n",
        "print(f'Probas: {probas}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_2lg9sIH8ro0",
        "outputId": "dad957dc-2a76-410d-8568-6e0742c2ab47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n",
            "Token IDs Shape: torch.Size([2, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(f'Token IDs: {token_ids}')\n",
        "print(f'Token IDs Shape: {token_ids.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y6GNh-Ou8ro1",
        "outputId": "2f2a209a-dd5c-4dd9-97d3-367645ff5b3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets Batch 1 :  effort moves you\n",
            "Output Batch 1:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "#token ids to output text\n",
        "\n",
        "target_batch_1 = token_ids_to_text(targets[0], tokenizer)\n",
        "output_batch_1 = token_ids_to_text(token_ids[0].flatten(), tokenizer)\n",
        "\n",
        "print(f'Targets Batch 1 : {target_batch_1}')\n",
        "print(f'Output Batch 1: {output_batch_1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVVeyj748ro2"
      },
      "source": [
        "#### 2. Text Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEo7t31I8ro3"
      },
      "source": [
        "1. `Logits`\n",
        "\n",
        "2. `Probabilities`\n",
        "\n",
        "3. `Target Probabilities`\n",
        "\n",
        "4. `Log Probabilities`\n",
        "\n",
        "5. `Average Log Probability`\n",
        "\n",
        "6. `Negative avg log probability`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_tg02EY48ro3",
        "outputId": "480dce50-9438-46e7-f935-4d002fe93354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3626, 6100,  345]), tensor([ 1107,   588, 11311]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "targets[0], targets[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MguEp1Lt8ro4",
        "outputId": "3243186a-c0d9-4a05-d6ef-50fe3abf1ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1 probability: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "Text 2 probability: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ],
      "source": [
        "# getting the probability scores corresponding to target tokens\n",
        "# Target Probabilities\n",
        "\n",
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
        "print(f'Text 1 probability: {target_probas_1}')\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
        "print(f'Text 2 probability: {target_probas_2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XkUHNZR38ro5",
        "outputId": "08967602-7569-4240-c900-133e0cfb3840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# log_probability\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "log_probas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmGyJYC-8ro6"
      },
      "source": [
        "Why log of probability scores\n",
        "1. stronger penalization for incorrect predictions.\n",
        "    - `prob = 0.9 => -log(0.9) = 0.10`\n",
        "    - `prob = 0.01 => -log(0.01) = 4.6`\n",
        "2. makes the loss func convex\n",
        "3. prevent numerical underflow\n",
        "4. handles zero prob, avoiding undefined gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wn6yZjab8ro6",
        "outputId": "009a9e49-421f-475e-d16f-b2b9d6e2f74f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-10.7940)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# avg log probabiltiy\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "avg_log_probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "99iRK4uU8ro6",
        "outputId": "b22d3661-e7f9-4993-9961-0cd358594e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.7940)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# neg avg log probability\n",
        "neg_avg_log_prob = avg_log_probas*-1\n",
        "neg_avg_log_prob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0HI_oLJ8ro7"
      },
      "source": [
        "`Cross Entropy Loss`: negative log-likelihood\n",
        "\n",
        "takes care of steps `2` to `5`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Os6ghycy8ro7",
        "outputId": "5e3a9b0a-b371-4484-b1f4-3fd2421e9a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits Shape: torch.Size([2, 3, 50257])\n",
            "Targets Shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "print(f'Logits Shape: {logits.shape}')\n",
        "print(f'Targets Shape: {targets.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-xtcCkk8ro8"
      },
      "source": [
        "Why flatten?\n",
        "\n",
        "because `cross_entropy()` expects `targets` to be 1D`[N]` and `logits` as 2D tensor`[N,C]`\n",
        "\n",
        "where\n",
        "* `N` = number of samples (batch_size * seq_length)\n",
        "\n",
        "* `C` = num of classes (vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5uJ-6g5c8ro8",
        "outputId": "a4e01516-9c1d-4e26-f2ae-5b222f292545",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened Logits Shape: torch.Size([6, 50257])\n",
            "Targets Logits Shape: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "# flatten these tensors\n",
        "\n",
        "logits_flat = logits.flatten(0,1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(f'Flattened Logits Shape: {logits_flat.shape}')\n",
        "print(f'Targets Logits Shape: {targets_flat.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rsBjYqaG8ro8",
        "outputId": "454cfb1b-00a1-4454-8040-39e2b8fbdd60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4IkSAuE8ro9"
      },
      "source": [
        "**Perplexity**\n",
        "- measures how well the prob distribution predicted by the model matches the actual distribution of words in the dataset\n",
        "- it quantifies uncertainty or randomness in predictions\n",
        "- lower = better model, higher = worse model\n",
        "- `perplexity = torch.exp(loss)`\n",
        "- more interpretable than raw_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xij_fMtH8ro9"
      },
      "source": [
        "#### Training and Validation losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VXs20WKQ8ro9",
        "outputId": "2687604f-51df-4811-c95b-aa4a60c89244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap g'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# fecthing the raw_data from the_verdict.txt file\n",
        "\n",
        "file_path = 'the-verdict.txt'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    text_data = file.read()\n",
        "\n",
        "text_data[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nr9keGOZ8ro-",
        "outputId": "42da6b34-b98e-4a68-b2ba-bb363a3b741d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 20479\n",
            "Total number of tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "total_chars = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(f'Total number of characters: {total_chars}')\n",
        "print(f'Total number of tokens: {total_tokens}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GAu5v5QK8ro-"
      },
      "outputs": [],
      "source": [
        "train_split = 0.9\n",
        "split_idx = int(train_split* len(text_data))\n",
        "\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "# train_data, val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-iXFQYd68ro_"
      },
      "outputs": [],
      "source": [
        "# training and validation dataloader\n",
        "\n",
        "from CustomDatasetDataloader import create_dataloders_v1\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataloader = create_dataloders_v1(\n",
        "    txt=train_data,\n",
        "    batch_size= 2,\n",
        "    max_length= GPT_CONFIG_124M['context_length'],\n",
        "    stride = GPT_CONFIG_124M['context_length'],\n",
        "    drop_last= True,\n",
        "    shuffle = True,\n",
        "    num_workers = 0)\n",
        "\n",
        "val_dataloader = create_dataloders_v1(\n",
        "    txt=val_data,\n",
        "    batch_size= 2,\n",
        "    max_length= GPT_CONFIG_124M['context_length'],\n",
        "    stride = GPT_CONFIG_124M['context_length'],\n",
        "    drop_last= False,\n",
        "    shuffle = False,\n",
        "    num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_dataloader:\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "zsGMVZN9HTUg",
        "outputId": "64030262-a4f2-46f0-d210-75ddf84555aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in val_dataloader:\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "O-zaaRv1Htpn",
        "outputId": "c5a83750-2427-40db-8345-d5a41b6520b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrXpaWaK8rpA"
      },
      "source": [
        "There are 9 training set batches with shape `[2, 256]` (i.e two samples and 256 tokens each) and 1 validation batch with shape `[2, 256]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IS18pOKh8rpB"
      },
      "outputs": [],
      "source": [
        "# cross entropy loss for a given batch\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "\n",
        "    logits = model(input_batch)\n",
        "    loss = F.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uPovecGV8rpB"
      },
      "outputs": [],
      "source": [
        "# computing loss over all the batches\n",
        "# using num_batches so that we can specify lesser number of batches\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0\n",
        "    if len(data_loader) ==0:\n",
        "        return float('nan')\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i< num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss/num_batches #avg loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2NWvs4IJ8rpC",
        "outputId": "48dec73a-d98f-4d17-be82-e77a4764cb6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.98758316040039\n",
            "Testing loss: 10.981104850769043\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_dataloader, model, device)\n",
        "    val_loss = calc_loss_loader(val_dataloader, model, device)\n",
        "\n",
        "print(f'Training loss: {train_loss}')\n",
        "print(f'Testing loss: {val_loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWHTs1q-8rpE"
      },
      "source": [
        "the loss values are high as we haven't trained our model yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQOx1rcs8rpE"
      },
      "source": [
        "#### Training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6hqHK2w98rpE"
      },
      "outputs": [],
      "source": [
        "# function for pretraining llm\n",
        "\n",
        "def train_model_simple(model,train_dataloader, val_dataloader, optimizer,\n",
        "                       device, num_epochs, eval_freq, eval_iter, start_context,\n",
        "                       tokenizer):\n",
        "    train_losses, val_losses, track_tokens_seen = [],[],[]\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for input_batch, target_batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step +=1\n",
        "\n",
        "            # evaluation step\n",
        "            if global_step % eval_freq ==0:\n",
        "                train_loss, val_loss = evaluate_model(model, train_dataloader,\n",
        "                                                      val_dataloader, device,\n",
        "                                                      eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f'Epoch: {epoch+1} | Step: {global_step:06d}')\n",
        "                print(f'Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}')\n",
        "\n",
        "        # prints a sample text after each epoch\n",
        "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwZOoPUi8rpF"
      },
      "source": [
        "`evaluate_model `->  prints train and val losses after each model update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "aJrgSTBy8rpH"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device,\n",
        "                                      num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device,\n",
        "                                    num_batches=eval_iter)\n",
        "\n",
        "        model.train()\n",
        "        return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwUrtlG88rpH"
      },
      "source": [
        "`generate_and_print_sample`: takes a text snippet as input, converts into token_ids -> feeds it to the llm -> generate a text sample using `generate_text_simple`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1cedokkZ8rpR"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(model, idx=encoded, max_new_tokens=50,\n",
        "                                         context_size=context_size)\n",
        "\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace('\\n', ' '))\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1KRUP-J8rpS"
      },
      "source": [
        "Training a `GPTModel` for 10 epochs.\n",
        "\n",
        "optimizer: `AdamW`\n",
        "\n",
        "lr = `0.0004`\n",
        "\n",
        "weight_decay = `0.1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0GwnAphv8rpT",
        "outputId": "4f9954b3-c88f-4664-ae63-5a898d715d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Step: 000000\n",
            "Train Loss: 9.818 | Val Loss: 9.930\n",
            "Epoch: 1 | Step: 000005\n",
            "Train Loss: 8.066 | Val Loss: 8.336\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Epoch: 2 | Step: 000010\n",
            "Train Loss: 6.623 | Val Loss: 7.053\n",
            "Epoch: 2 | Step: 000015\n",
            "Train Loss: 6.047 | Val Loss: 6.605\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Epoch: 3 | Step: 000020\n",
            "Train Loss: 5.532 | Val Loss: 6.507\n",
            "Epoch: 3 | Step: 000025\n",
            "Train Loss: 5.399 | Val Loss: 6.389\n",
            "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
            "Epoch: 4 | Step: 000030\n",
            "Train Loss: 4.895 | Val Loss: 6.280\n",
            "Epoch: 4 | Step: 000035\n",
            "Train Loss: 4.648 | Val Loss: 6.304\n",
            "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
            "Epoch: 5 | Step: 000040\n",
            "Train Loss: 4.023 | Val Loss: 6.165\n",
            "Every effort moves you know                                                 \n",
            "Epoch: 6 | Step: 000045\n",
            "Train Loss: 3.625 | Val Loss: 6.172\n",
            "Epoch: 6 | Step: 000050\n",
            "Train Loss: 3.045 | Val Loss: 6.144\n",
            "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
            "Epoch: 7 | Step: 000055\n",
            "Train Loss: 2.948 | Val Loss: 6.183\n",
            "Epoch: 7 | Step: 000060\n",
            "Train Loss: 2.230 | Val Loss: 6.128\n",
            "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
            "Epoch: 8 | Step: 000065\n",
            "Train Loss: 1.774 | Val Loss: 6.162\n",
            "Epoch: 8 | Step: 000070\n",
            "Train Loss: 1.475 | Val Loss: 6.229\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
            "Epoch: 9 | Step: 000075\n",
            "Train Loss: 1.135 | Val Loss: 6.268\n",
            "Epoch: 9 | Step: 000080\n",
            "Train Loss: 0.858 | Val Loss: 6.298\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
            "Epoch: 10 | Step: 000085\n",
            "Train Loss: 0.627 | Val Loss: 6.382\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(config=GPT_CONFIG_124M)\n",
        "\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay = 0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, token_seen = train_model_simple(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    device,\n",
        "    num_epochs,\n",
        "    eval_freq=5,\n",
        "    eval_iter=5,\n",
        "    start_context=\"Every effort moves you\",\n",
        "    tokenizer= tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bag-P4Wo8rpT"
      },
      "source": [
        "Plotting Training and Validation losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tk_w3jNC8rpT",
        "outputId": "6ba184df-4194-4892-af89-433e194df990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "# MaxNLocator -> tries to select resonable num of ticks with integer values instead of decimel points\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize =(5,3))\n",
        "    ax1.plot(epochs_seen, train_losses, label= 'Training Loss')\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle ='-.', label = 'Validation Loss')\n",
        "\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend(loc= 'upper right')\n",
        "\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer = True))\n",
        "    ax2 = ax1.twiny() # creates a twin x-axis (shared y-axis) for existing axis ax1\n",
        "\n",
        "    ax2.plot(token_seen, train_losses, alpha=0) # alpha = 0 -> invisible plot\n",
        "    ax2.set_xlabel('Tokens seen')\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like our model is overfitting to the training data"
      ],
      "metadata": {
        "id": "ZVoHBVpkkEAC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJhjPUce8rpU"
      },
      "source": [
        "#### Decoding Strategies\n",
        "ways to introduce randomness in the output.\n",
        "\n",
        "1. *temperature scaling*\n",
        "\n",
        "2. *top-k sampling*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4os5eAG58rpU",
        "outputId": "8879bd98-bc62-446b-b745-2806fc4785d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text: Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# print output text using our pretrained model\n",
        "\n",
        "model.to('cpu')\n",
        "model.eval()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "token_ids = generate_text_simple(model= model,\n",
        "                                 idx= text_to_token_ids('Every effort moves you', tokenizer),\n",
        "                                 max_new_tokens= 25,\n",
        "                                 context_size= GPT_CONFIG_124M['context_length'])\n",
        "\n",
        "\n",
        "print(f'Output text: {token_ids_to_text(token_ids, tokenizer)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npehHEyQ8rpV"
      },
      "source": [
        "currently our pretrained llm will generate same output even if we run the above cell multiple times...keeping the `start_context` same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PxhvvUe8rpV"
      },
      "source": [
        "in `generate_text_simple` we are selecting token with max probability as next token...known as greddy decoding.\n",
        "\n",
        "now, we will use probabilistic sampling for next token selection using `torch.multinomial`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vu_AiBij8rpW",
        "outputId": "9083f73f-f3f0-405b-df0f-ab08af287598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('forward',\n",
              " tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
              "         1.0120e-04, 3.5758e-01, 4.0122e-03]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# illustration\n",
        "\n",
        "import torch\n",
        "\n",
        "vocab ={\"closer\": 0,\n",
        "        \"every\": 1,\n",
        "        \"effort\": 2,\n",
        "        \"forward\": 3,\n",
        "        \"inches\": 4,\n",
        "        \"moves\": 5,\n",
        "        \"pizza\": 6,\n",
        "        \"toward\": 7,\n",
        "        \"you\": 8}\n",
        "\n",
        "inv_vocab = {v:k for k, v in vocab.items()}\n",
        "\n",
        "\n",
        "# let's say llm returns following next-token logits given start_context ='Every effort moves you'\n",
        "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
        "\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "inv_vocab[next_token_id], probas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.multinomial()`: to sample elements from a given probability distribution"
      ],
      "metadata": {
        "id": "FjlHFbE2mXHJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UulKiKpL8rpW",
        "outputId": "7ceab7d4-354b-4e00-e246-c8d88fe9e199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'toward'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# let's do the same using probabilistic sampling\n",
        "\n",
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "inv_vocab[next_token_id]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "tYZ13Yf_8rpX",
        "outputId": "1a9645bd-bcaa-4746-dbe0-e7aef95af23e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 X closer\n",
            "2 X every\n",
            "0 X effort\n",
            "544 X forward\n",
            "2 X inches\n",
            "1 X moves\n",
            "0 X pizza\n",
            "376 X toward\n",
            "4 X you\n"
          ]
        }
      ],
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123)\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]  # 1_000 is same as 1000(just for better readability)\n",
        "\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample)) # to count occurence\n",
        "\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f'{freq} X {inv_vocab[i]}')\n",
        "\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or3KXhzg8rpX"
      },
      "source": [
        "`temperature scaling` -> logits divided by some number > 0\n",
        "\n",
        "temperature scaling is used to calibrate the confidence of a classification model;s predicted probabilities\n",
        "\n",
        "1. T = 1, normal softmax\n",
        "2. T> 1, softens probas (dec confidence)\n",
        "3. T< 1, sharpens probas (inc confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jajTa21G8rpY"
      },
      "outputs": [],
      "source": [
        "def softmax_with_temp(logits, temp):\n",
        "    scaled_logits = logits/temp\n",
        "    return torch.softmax(scaled_logits, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "NuRE1ZB68rpZ",
        "outputId": "44c67d7b-5363-49d3-fca2-7e95d95feeef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# illustration\n",
        "\n",
        "temps =[1,0.1,5]\n",
        "scaled_probas = [softmax_with_temp(next_token_logits, t) for t in temps]\n",
        "\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize= (5,3))\n",
        "for i, t in enumerate(temps):\n",
        "    rects = ax.bar(x+ i*bar_width, height=scaled_probas[i], width= bar_width,\n",
        "                   label= f'Temperature= {t}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher temperature -> more uniformly distributed probabilities"
      ],
      "metadata": {
        "id": "fPHtXK9qoqac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Top-k Sampling` -> limits sampling to k most probable tokens and exclude all other tokens by masking their probability scores"
      ],
      "metadata": {
        "id": "Vr-qs_59o8tt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "wO6ovj6w8rpa",
        "outputId": "cd5c79e7-0881-420e-e081-6d2d536fa2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topk logits tensor([6.7500, 6.2800, 4.5100])\n",
            "topk indices tensor([3, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "top_k = 3\n",
        "topk_logits, topk_indices = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "print('topk logits', topk_logits)\n",
        "print('topk indices', topk_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting logits below the minimum topk_logits equal to -inf\n",
        "\n",
        "new_logits = torch.where(condition=next_token_logits < topk_logits.min(),\n",
        "                         input=torch.tensor(-float('inf')),\n",
        "                         other=next_token_logits)\n",
        "print(new_logits)"
      ],
      "metadata": {
        "id": "sCERmwcLqSIm",
        "outputId": "21a21406-c1ab-4519-9833-3b3abdf93461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = F.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "id": "A54Husruq5W5",
        "outputId": "fab3e425-9f52-4cf2-ad3a-cc014c7c686e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can apply temperature scaling and multinomial function on these topk_probas"
      ],
      "metadata": {
        "id": "UeW3_2UyrHa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify the generate_text_simple function\n",
        "\n",
        "def generate(model,idx, max_new_tokens, context_size, temp=0.0,\n",
        "             top_k = None, eos_id = None):\n",
        "  for _ in range(max_new_tokens):\n",
        "        # crops the current context(initial tokens) to fit model's max context size\n",
        "        idx_cond = idx[:,-context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)  # shape (batch, n_token, vocab_size)\n",
        "\n",
        "        logits = logits[:, -1, :]  # to extracts the last vector, shape -> (batch, vocab_size)\n",
        "\n",
        "        if top_k is not None:\n",
        "          topk_logits, _= torch.topk(logits, top_k)\n",
        "          logits = torch.where(condition=logits < topk_logits.min(),\n",
        "                               input=torch.tensor(-float('inf')).to(logits.device),\n",
        "                               other=logits)\n",
        "\n",
        "        if temp >0.0:\n",
        "          logits = logits/temp\n",
        "          probs = F.softmax(logits, dim=-1)\n",
        "          idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "          idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        if eos_id is not None and idx_next == eos_id:\n",
        "          break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx\n"
      ],
      "metadata": {
        "id": "2qDFRN7zrCU5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "    model= model,\n",
        "    idx= text_to_token_ids('Every effort moves you', tokenizer),\n",
        "    max_new_tokens= 20,\n",
        "    context_size= GPT_CONFIG_124M['context_length'],\n",
        "    top_k=30,\n",
        "    temp= 1.5,\n",
        ")\n",
        "\n",
        "print(f'Output Text: \\n {token_ids_to_text(token_ids, tokenizer)}')"
      ],
      "metadata": {
        "id": "86XefeqEtS8W",
        "outputId": "88e6e029-984f-489f-abd1-13b933286874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Text: \n",
            " Every effort moves you know began to happen a hint a little it was such a good; and watched at the end would\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving and loading the model"
      ],
      "metadata": {
        "id": "XQmRlcIguiS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'pretrained_gpt2_model.pth')"
      ],
      "metadata": {
        "id": "2XT3eH_7tw74"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"pretrained_gpt2_model.pth\"\n",
        "size_in_bytes = os.path.getsize(file_path)\n",
        "print(f\"File size: {size_in_bytes/(1024*1024)} MB\")\n"
      ],
      "metadata": {
        "id": "WKsncS_yu0xv",
        "outputId": "9143c8c3-1312-4496-f819-1dc11b217d52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 622.6430110931396 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the model\n",
        "\n",
        "model= GPTModel(config=GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load('pretrained_gpt2_model.pth',map_location= device))\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "mWooN2mavLa7"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model and optimizer both\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict()\n",
        "}, 'model_and_optimizer.pth')"
      ],
      "metadata": {
        "id": "idyXJzY8v43E"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model and optimizer\n",
        "\n",
        "checkpoint = torch.load('model_and_optimizer.pth', map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "model.train();"
      ],
      "metadata": {
        "id": "YABKyhtawSFb"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jM3fQAzKwqEF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}